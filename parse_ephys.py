##parse_ephys.py
##this function works with trial timestamps generated by 
##parse_timestamps.py. It splits whole session ephys data
##into individual trials, as well as individual behavioral events

import os
import glob
import numpy as np
#import plxread
import h5py

####TODO: plxread not install correctly!######



"""
this script looks in a directory, takes the plx files and saves a copy as an HDF5 file.

"""
def batch_plx_to_hdf5(directory):
	##first, get a list of the plx files in the directory:
	cd = os.getcwd() ##to return to the cd later
	os.chdir(directory)
	for f in glob.glob("*.plx"):
		cur_file = os.path.join(directory,f)
		print "Saving "+cur_file
		##parse the plx file
		data = plxread.import_file(cur_file,AD_channels=range(1,97),import_unsorted=False,
			verbose=False,import_wf=True)
		##create the output file in the same dir
		out_file = h5py.File(cur_file.strip('plx')+'hdf5','w-')
		##save the data
		for k in data.keys():
			out_file.create_dataset(k,data=data[k])
	out_file.close()
	os.chdir(cd)
	print "Done!"
	return None

"""
This function returns a dictionary of spike data, in binary form, 
given an input hdf5 file.
Inputs:
	-f_in: an hdf5 file with the ephys data
Outputs:
	-result: a dictionary where the keys are unit names and the values
		are binary arrays of the spike data
"""
def get_spike_data(f_in):
	##dict to return 
	result = {}
	##get the duration of this session in ms
	duration = get_session_duration(f_in)
	##open our source file
	f = h5py.File(f_in,'r')
	##get the names of all the sorted units contained in this file
	units_list = [x for x in f.keys() if x.startswith("sig")]
	##process each of these sorted units, and add the data to the result dict
	for unit in units_list:
		signal = np.asarray(f[unit])
		##convert the signal to a binary array
		signal = pt_times_to_binary(signal,duration)
		##add to the result
		result[unit] = signal
	return result
"""
This script takes in a 1-D array of timestamps, a single ephys signal (1-D)
and returns the windowed data around the timestamps.
Input:
	-1-D array of timstamps (in sec)
	-1-D array of signal (sampled in ms)
	-Window size (in sec)
Output: 
	-an x-timestamps by n ms array of the windowed data
	-a 1-D array that indicates the indices (if any) of the windows
		/ trials contains no data
"""
def data_windows(timestamps,signal,window=[3,3]):
	##get rid of singleton dims
	timestamps = np.squeeze(timestamps)
	signal = np.squeeze(signal)
	##pad the data so you can take windows at the edge
	pad_1 = np.zeros(abs(window[0])*1000)
	pad_2 = np.zeros(abs(window[1])*1000)
	signal = np.hstack((pad_1,signal,pad_2))
	##shift the timestamps to account for padding
	timestamps = timestamps+window[0]
	##allocate memory
	result = np.zeros((timestamps.size,(window[0]*1000+window[1]*1000)))
	for i in range(timestamps.size):
		start = np.ceil((timestamps[i]*1000.0-window[0]*1000.0)).astype(int)
		stop = np.ceil((timestamps[i]*1000.0+window[1]*1000.0)).astype(int)
		idx = np.arange(start,stop)
		result[i,:] = signal[idx]
	##now check if there are any empty trials
	row_total = result.sum(axis=1)
	no_data = np.where(row_total==0)
	return result,no_data


"""
This function returns a dictionary with all the data windows
around ONE set of timestamps for ALL sorted neurons in a file.
Inputs:
	-f_in: HDF5 file containing ephys data
	-timestamps: timestamps to lock to 
	-window_size: list, with [-3,3] corresponding to 3 secs before and 3 after
Outputs:
	-result: dictionary containing the windows, where the keys are 
		the names of the individual units
"""
def data_windows_multi(f_in,timestamps,window=[3,3]):
	##dict to return 
	result = {}
	##get the duration of this session in ms
	duration = get_session_duration(f_in)
	##open our source file
	f = h5py.File(f_in,'r')
	##get the names of all the sorted units contained in this file
	units_list = [x for x in f.keys() if x.startswith("sig")]
	##process each of these sorted units, and add the data to the result dict
	for unit in units_list:
		signal = np.asarray(f[unit])
		##convert the signal to a binary array
		signal = pt_times_to_binary(signal,duration)
		##get the data windows for this unit
		windows,no_data = data_windows(timestamps,signal,window)
		##add to the result
		result[unit] = windows
	return result

"""
a helper function to convert spike times to a binary array
ie, an array where each bin is a ms, and a 1 indicates a spike 
occurred and a 0 indicates no spike
Inputs:
	-signal: an array of spike times in s(!)
	-duration: length of the recording in ms(!)
Outputs:
	-A duration-length 1-d array as described above
"""
def pt_times_to_binary(signal, duration):
	##convert the spike times to ms
	signal = signal*1000.0
	##get recodring length
	duration = float(duration)
	##set the number of bins as the next multiple of 100 of the recoding duration;
	#this value will be equivalent to the number of milliseconds in 
	#the recording (plus a bit more)
	numBins = int(np.ceil(duration/100)*100)
	##do a little song and dance to ge the spike train times into a binary format
	bTrain = np.histogram(signal,bins=numBins,range=(0,numBins))
	bTrain = bTrain[0].astype(bool).astype(int)
	return bTrain

"""
A helper function to get the duration of a session.
Operates on the principal that the session duration is
equal to the length of the LFP (slow channel, A/D) recordings 
Inputs:
	-file path of an hdf5 file with the ephys data
Outputs:
	-duration of the session in ms(!), as an integer rounded up
"""
def get_session_duration(f_in):
	f = h5py.File(f_in, 'r')
	##get a list of the LFP channel timestamp arrays
	##(more accurate than the len of the value arrs in cases where
	##the recording was paused)
	AD_ts = [x for x in f.keys() if x.endswith('_ts')]
	##They should all be the same, so just get the first one
	sig = AD_ts[0]
	duration = np.ceil(f[sig][-1]*1000.0).astype(int)
	f.close()
	return duration
